import pandas as pd
import numpy as np
from datetime import timedelta
import logging
import gc

def preprocess_data(df):
    """ë°ì´í„° ì „ì²˜ë¦¬"""
    try:
        logging.info("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # ì‹œê°„ ì»¬ëŸ¼ ë³€í™˜
        if 'inserted_at' in df.columns:
            df['inserted_at'] = pd.to_datetime(df['inserted_at'])
        
        # ì •ë ¬
        df = df.sort_values(by="inserted_at")
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df.dropna()
        
        logging.info(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {df.shape}")
        return df
        
    except Exception as e:
        logging.error(f"âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise

def predict_next_row(df, models, scalers, target_columns, feature_columns, lookback_window=12):
    """ë‹¤ìŒ 30ë¶„ í›„ ì˜ˆì¸¡ - ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ """
    try:
        logging.info("ğŸ”® ì˜ˆì¸¡ í•¨ìˆ˜ ì‹œì‘...")
        
        # ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        recent_data = df.tail(lookback_window)
        
        # í”¼ì²˜ í–‰ êµ¬ì„±
        feature_row = []
        
        for col in feature_columns:
            if col in recent_data.columns:
                val = recent_data[col].values[-1]
                # NaN ì²´í¬
                if pd.isna(val):
                    val = 0
            else:
                val = 0
            feature_row.append(val)
        
        # ì‹œê°„ íŠ¹ì„± ì¶”ê°€
        last_time = df.iloc[-1]['inserted_at']
        next_time = pd.to_datetime(last_time) + timedelta(minutes=30)
        
        # ì‹œê°„ íŠ¹ì„± ì¶”ê°€
        feature_row.extend([next_time.hour, next_time.weekday(), next_time.month])
        
        logging.info(f"ğŸ“Š í”¼ì²˜ í–‰ í¬ê¸°: {len(feature_row)}")
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜
        feature_array = np.array(feature_row).reshape(1, -1)
        
        # ìŠ¤ì¼€ì¼ë§
        feature_scaled = scalers['feature_scaler'].transform(feature_array)
        
        logging.info("ğŸ”„ ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘...")
        
        # ì˜ˆì¸¡ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ)
        predictions = {}
        
        for i, col in enumerate(target_columns):
            try:
                model = models[col]
                target_scaler = scalers[f"{col}_scaler"]
                
                # ì˜ˆì¸¡ ìˆ˜í–‰
                pred_scaled = model.predict(feature_scaled)
                
                # ìŠ¤ì¼€ì¼ ì—­ë³€í™˜
                pred_original = target_scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()[0]
                
                predictions[col] = pred_original
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del pred_scaled
                
                if (i + 1) % 10 == 0:  # 10ê°œë§ˆë‹¤ ë¡œê·¸
                    logging.info(f"ğŸ“ˆ ì˜ˆì¸¡ ì§„í–‰: {i+1}/{len(target_columns)}")
                    gc.collect()
                
            except Exception as e:
                logging.error(f"âŒ {col} ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                predictions[col] = 0  # ê¸°ë³¸ê°’ ì„¤ì •
        
        # ê²°ê³¼ DataFrame ìƒì„±
        pred_row = predictions.copy()
        pred_row["inserted_at"] = next_time
        pred_row["hour"] = next_time.hour
        pred_row["day_of_week"] = next_time.weekday()
        pred_row["month"] = next_time.month
        
        result_df = pd.DataFrame([pred_row])
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del feature_array, feature_scaled, predictions, pred_row
        gc.collect()
        
        logging.info("âœ… ì˜ˆì¸¡ ì™„ë£Œ")
        
        return result_df
        
    except Exception as e:
        logging.error(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logging.error(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        raise